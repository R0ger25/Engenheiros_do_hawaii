{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10094498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7a8a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Configurações de pastas e arquivos\n",
    "# -----------------------------\n",
    "output_dir = \"resultado_experimento3\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30c43b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_file = os.path.join(output_dir, \"modelo1_gpt4_gerado.txt\")  # você coloca manualmente\n",
    "llama_file = os.path.join(output_dir, \"modelo2_llama3_gerado.txt\")\n",
    "comparacao_file = os.path.join(output_dir, \"comparacao_final.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c8c3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL_NAME = \"llama3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7600f0e7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Prompt LLaMA-3\n",
    "# -----------------------------\n",
    "PROMPT = (\n",
    "    \"Aja como um letrista de rock brasileiro dos anos 80/90, similar a Humberto Gessinger.\\n\"\n",
    "    \"Suas letras são filosóficas, irônicas, céticas e usam muitas metáforas sobre tecnologia, \"\n",
    "    \"a passagem do tempo, solidão urbana e crítica social.\\n\"\n",
    "    \"Use um vocabulário rico, jogos de palavras, referências literárias e termos técnicos ou científicos.\\n\"\n",
    "    \"Aqui estão alguns exemplos curtos de letras do Engenheiros do Hawaii para referência:\\n\"\n",
    "    \"1. 'O papa é pop, o pop não poupa ninguém...'\\n\"\n",
    "    \"2. 'Eu me sinto um estrangeiro, passageiro de algum trem...'\\n\"\n",
    "    \"3. 'Toda a infância em versos e canções, como mapas de ilusões...'\\n\"\n",
    "    \"Tema: 'a ansiedade na era digital'.\\n\"\n",
    "    \"Tarefa: Escreva uma letra original e completa entre 14 e 40 linhas. Apenas a letra.\\n\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75b0e89f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Função para gerar LLaMA-3\n",
    "# -----------------------------\n",
    "def call_ollama_stream(model, prompt):\n",
    "    payload = {\"model\": model, \"prompt\": prompt}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    with requests.post(OLLAMA_URL, json=payload, headers=headers, stream=True, timeout=200) as r:\n",
    "        r.raise_for_status()\n",
    "        for line in r.iter_lines():\n",
    "            if not line:\n",
    "                continue\n",
    "            data = json.loads(line.decode(\"utf-8\"))\n",
    "            if \"response\" in data:\n",
    "                yield data[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0be2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando texto do LLaMA-3:\n",
      "\n",
      "Aqui vai minha tentativa de escrever uma letra inspirada no estilo dos Engenheiros do Hawaii:\n",
      "\n",
      "Nos terminais, cumplicidades se estabelecem\n",
      "Em linguagem de bits, o coração não se comunica\n",
      "Ouvimos os gritos das conexões que falham\n",
      "E a solidão é um bug que nunca é resolvido\n",
      "\n",
      "A ansiedade digital, uma doença contagiosa\n",
      "Que nos faz crer que sempre podemos atualizar\n",
      "Mas no fundo, as preocupações são apenas\n",
      "Um loop infinito de inquietude e dúvida\n",
      "\n",
      "Talvez seja o reflexo da velocidade do tempo\n",
      "Que nos faz sentir como fragmentos de código\n",
      "Desconectados, sem um lugar para pertencer\n",
      "A não ser à espera da próxima atualização\n",
      "\n",
      "Mas eu me pergunto: há um programa que possa\n",
      "Reprogramar a nossa alma, torná-la mais humana?\n",
      "Ou é apenas uma questão de algoritmos e recursos?\n",
      "E o que acontece quando o sistema falha?\n",
      "\n",
      "Nossa existência é um bug, um erro de compilação\n",
      "Que precisa ser resolvido em tempo real\n",
      "Mas a ansiedade digital, ela é o sintoma\n",
      "De uma doença mais profunda, de uma perda de identidade\n",
      "\n",
      "E assim nos tornamos escravos das notificações\n",
      "E nossas vidas são um fluxo constante de informações\n",
      "Mas eu me pergunto: há um botão para parar?\n",
      "Ou é apenas um clique para nos tornarmos again?"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Gerando texto LLaMA-3\n",
    "# -----------------------------\n",
    "output_text = \"\"\n",
    "print(\"Gerando texto do LLaMA-3:\\n\")\n",
    "for chunk in call_ollama_stream(MODEL_NAME, PROMPT):\n",
    "    print(chunk, end=\"\")\n",
    "    output_text += chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb1ebccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(llama_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd0dac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Letra LLaMA-3 salva em: resultado_experimento3\\modelo2_llama3_gerado.txt\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\\nLetra LLaMA-3 salva em: {llama_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79219f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Lendo GPT-4 e LLaMA-3\n",
    "# -----------------------------\n",
    "with open(gpt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    gpt_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b8392bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(llama_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    llama_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c88a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Comparação\n",
    "# -----------------------------\n",
    "total_original = 672897  # fornecido no enunciado\n",
    "len_gpt = len(gpt_text)\n",
    "len_llama = len(llama_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "697701c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_lines = set(gpt_text.splitlines())\n",
    "llama_lines = set(llama_text.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "919cdea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_only = gpt_lines - llama_lines\n",
    "llama_only = llama_lines - gpt_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a706aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Salvando comparação\n",
    "# -----------------------------\n",
    "with open(comparacao_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"==========================\\n\")\n",
    "    f.write(\" COMPARAÇÃO ENTRE MODELOS \\n\")\n",
    "    f.write(\"==========================\\n\\n\")\n",
    "    f.write(f\"▶ Total de caracteres das letras originais: {total_original}\\n\")\n",
    "    f.write(f\"▶ Tamanho do texto do Modelo 1 (GPT-4): {len_gpt} caracteres\\n\")\n",
    "    f.write(f\"▶ Tamanho do texto do Modelo 2 (LLaMA-3): {len_llama} caracteres\\n\\n\")\n",
    "    f.write(\"======================================================\\n\")\n",
    "    f.write(\"SEMELHANÇAS (PARA O SEU RELATÓRIO):\\n\")\n",
    "    f.write(\"- Ambos usam metáforas\\n\")\n",
    "    f.write(\"- Ambos abordam temas existenciais\\n\")\n",
    "    f.write(\"- Ambos seguem vocabulário filosófico/poético\\n\\n\")\n",
    "    f.write(\"======================================================\\n\")\n",
    "    f.write(\"DIFERENÇAS ENTRE AS LETRAS GERADAS\\n\\n\")\n",
    "    f.write(\"--- Trechos presentes APENAS no GPT-4 ---\\n\")\n",
    "    f.write(\"\\n\".join(sorted(gpt_only)))\n",
    "    f.write(\"\\n\\n--- Trechos presentes APENAS no LLaMA-3 ---\\n\")\n",
    "    f.write(\"\\n\".join(sorted(llama_only)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ea62e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparação salva em: resultado_experimento3\\comparacao_final.txt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comparação salva em: {comparacao_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "014d6fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimento 3 concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Fim do Script\n",
    "# -----------------------------\n",
    "print(\"\\nExperimento 3 concluído com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
